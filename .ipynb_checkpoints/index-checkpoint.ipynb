{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24f4081",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b91d04ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random # To generate random responses\n",
    "import string # For removing punctuation - data preprocessing\n",
    "import numpy as np # Handling arrays\n",
    "import io # Provides Pythonâ€™s main facilities for dealing with various types of I/O - text, binary and raw I/O\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Data encoding\n",
    "from sklearn.metrics.pairwise import cosine_similarity # Similarity-based response generation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer #Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17449a7b",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981ca7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize():\n",
    "    file = open('corpus.txt','r', errors = 'ignore')\n",
    "    corpus = file.read()\n",
    "    sentence_tokens = nltk.sent_tokenize(corpus)\n",
    "    word_tokens = nltk.word_tokenize(corpus)\n",
    "    return sentence_tokens, word_tokens\n",
    "    #print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b125349d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Francine Sandra Rivers (born 1947) is an American author of fiction with Christian themes, including inspirational romance novels.',\n",
       "  'Prior to becoming a born-again Christian in 1986, Rivers wrote historical romance novels.',\n",
       "  'She is best known for her inspirational\\nnovel Redeeming Love, while another novel, The Last Sin Eater, received its own film adaptation released in 2007 by Fox Faith.',\n",
       "  'A film based on Redeeming Love was released on January 21, 2022 through Pinnacle Peak Pictures and Universal Pictures.',\n",
       "  'Francine Rivers is the daughter of a police officer and a nurse.',\n",
       "  'From the time she was a child, Rivers wanted to be a published \\nauthor.',\n",
       "  'She attended Amador Valley High School in Pleasanton, CA.',\n",
       "  'She attended the University of Nevada, Reno, where she graduated\\n with a Bachelor of Arts degree in English and journalism.',\n",
       "  'After her graduation she spent time as a newspaper reporter, writing obituaries and human interest stories.'],\n",
       " ['Francine',\n",
       "  'Sandra',\n",
       "  'Rivers',\n",
       "  '(',\n",
       "  'born',\n",
       "  '1947',\n",
       "  ')',\n",
       "  'is',\n",
       "  'an',\n",
       "  'American',\n",
       "  'author',\n",
       "  'of',\n",
       "  'fiction',\n",
       "  'with',\n",
       "  'Christian',\n",
       "  'themes',\n",
       "  ',',\n",
       "  'including',\n",
       "  'inspirational',\n",
       "  'romance',\n",
       "  'novels',\n",
       "  '.',\n",
       "  'Prior',\n",
       "  'to',\n",
       "  'becoming',\n",
       "  'a',\n",
       "  'born-again',\n",
       "  'Christian',\n",
       "  'in',\n",
       "  '1986',\n",
       "  ',',\n",
       "  'Rivers',\n",
       "  'wrote',\n",
       "  'historical',\n",
       "  'romance',\n",
       "  'novels',\n",
       "  '.',\n",
       "  'She',\n",
       "  'is',\n",
       "  'best',\n",
       "  'known',\n",
       "  'for',\n",
       "  'her',\n",
       "  'inspirational',\n",
       "  'novel',\n",
       "  'Redeeming',\n",
       "  'Love',\n",
       "  ',',\n",
       "  'while',\n",
       "  'another',\n",
       "  'novel',\n",
       "  ',',\n",
       "  'The',\n",
       "  'Last',\n",
       "  'Sin',\n",
       "  'Eater',\n",
       "  ',',\n",
       "  'received',\n",
       "  'its',\n",
       "  'own',\n",
       "  'film',\n",
       "  'adaptation',\n",
       "  'released',\n",
       "  'in',\n",
       "  '2007',\n",
       "  'by',\n",
       "  'Fox',\n",
       "  'Faith',\n",
       "  '.',\n",
       "  'A',\n",
       "  'film',\n",
       "  'based',\n",
       "  'on',\n",
       "  'Redeeming',\n",
       "  'Love',\n",
       "  'was',\n",
       "  'released',\n",
       "  'on',\n",
       "  'January',\n",
       "  '21',\n",
       "  ',',\n",
       "  '2022',\n",
       "  'through',\n",
       "  'Pinnacle',\n",
       "  'Peak',\n",
       "  'Pictures',\n",
       "  'and',\n",
       "  'Universal',\n",
       "  'Pictures',\n",
       "  '.',\n",
       "  'Francine',\n",
       "  'Rivers',\n",
       "  'is',\n",
       "  'the',\n",
       "  'daughter',\n",
       "  'of',\n",
       "  'a',\n",
       "  'police',\n",
       "  'officer',\n",
       "  'and',\n",
       "  'a',\n",
       "  'nurse',\n",
       "  '.',\n",
       "  'From',\n",
       "  'the',\n",
       "  'time',\n",
       "  'she',\n",
       "  'was',\n",
       "  'a',\n",
       "  'child',\n",
       "  ',',\n",
       "  'Rivers',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'published',\n",
       "  'author',\n",
       "  '.',\n",
       "  'She',\n",
       "  'attended',\n",
       "  'Amador',\n",
       "  'Valley',\n",
       "  'High',\n",
       "  'School',\n",
       "  'in',\n",
       "  'Pleasanton',\n",
       "  ',',\n",
       "  'CA',\n",
       "  '.',\n",
       "  'She',\n",
       "  'attended',\n",
       "  'the',\n",
       "  'University',\n",
       "  'of',\n",
       "  'Nevada',\n",
       "  ',',\n",
       "  'Reno',\n",
       "  ',',\n",
       "  'where',\n",
       "  'she',\n",
       "  'graduated',\n",
       "  'with',\n",
       "  'a',\n",
       "  'Bachelor',\n",
       "  'of',\n",
       "  'Arts',\n",
       "  'degree',\n",
       "  'in',\n",
       "  'English',\n",
       "  'and',\n",
       "  'journalism',\n",
       "  '.',\n",
       "  'After',\n",
       "  'her',\n",
       "  'graduation',\n",
       "  'she',\n",
       "  'spent',\n",
       "  'time',\n",
       "  'as',\n",
       "  'a',\n",
       "  'newspaper',\n",
       "  'reporter',\n",
       "  ',',\n",
       "  'writing',\n",
       "  'obituaries',\n",
       "  'and',\n",
       "  'human',\n",
       "  'interest',\n",
       "  'stories',\n",
       "  '.'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca0136",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c756d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d55d00f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemTokens(tokens):\n",
    "    lst = []\n",
    "    for i in tokens: #Every individual token has to be lemmatized\n",
    "        lst.append(lemmatizer.lemmatize(i))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ab25cb",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "###### Noise removal of special characters - punctuation marks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9295b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbd5955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = dict((ord(i), None) for i in string.punctuation)\n",
    "# ord -> the inbuilt function in python for returning Unicode value of a corresponding character.\n",
    "# Each value is replaced with \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d3b3fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{33: None,\n",
       " 34: None,\n",
       " 35: None,\n",
       " 36: None,\n",
       " 37: None,\n",
       " 38: None,\n",
       " 39: None,\n",
       " 40: None,\n",
       " 41: None,\n",
       " 42: None,\n",
       " 43: None,\n",
       " 44: None,\n",
       " 45: None,\n",
       " 46: None,\n",
       " 47: None,\n",
       " 58: None,\n",
       " 59: None,\n",
       " 60: None,\n",
       " 61: None,\n",
       " 62: None,\n",
       " 63: None,\n",
       " 64: None,\n",
       " 91: None,\n",
       " 92: None,\n",
       " 93: None,\n",
       " 94: None,\n",
       " 95: None,\n",
       " 96: None,\n",
       " 123: None,\n",
       " 124: None,\n",
       " 125: None,\n",
       " 126: None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "280f1fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff433e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization and lemmatization\n",
    "def lemmer(text):\n",
    "    tokenized_text = nltk.word_tokenize(text.lower().translate(punct)) #Tokenization of text and Removal of punctuation\n",
    "    lemmatized_values = lemTokens(tokenized_text) # Calling the lemTokens function\n",
    "    return lemmatized_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e6912b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'have', 'a', 'headache']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test of lemmer function\n",
    "lemmer(\"I hav$$$$e a hea**dache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f68c45c",
   "metadata": {},
   "source": [
    "# Greeting - Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdfa06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting_inputs = ['hi','hello','hey', 'greetings']\n",
    "greeting_responses = ['Hi, My name is ChatBot. How may I help you?', 'Hey, My name is ChatBot. How may I help you?','Hello, My name is ChatBot. How may I help you?','Greetings, My name is ChatBot. How may I help you?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8ba8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greeting(text):\n",
    "    for token in text.split():\n",
    "        if token.lower() in greeting_inputs:\n",
    "            return random.choice(greeting_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "018ba4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi, My name is ChatBot. How may I help you?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the greeting function\n",
    "greeting(\"Hello I need some help in JavaScript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44cd870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitation - If we type an input \"Hello,\" like a greeting then followed comma, the chatbot won't recognize it as a greeting\n",
    "greeting(\"Hello, I need some help in Javacript\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a00650a",
   "metadata": {},
   "source": [
    "# Responses - Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "640803bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(text):\n",
    "    bot_response = ''\n",
    "\n",
    "    # Tokenize the user query\n",
    "    sent_tokens, word_tokens = tokenize()\n",
    "    sent_tokens.append(user_query)\n",
    "\n",
    "    # Data encoding -> Converting sent_tokens to vectors\n",
    "    tfidf_obj = TfidfVectorizer(tokenizer = lemmer, stop_words = \"english\" )\n",
    "    tfidf = tfidf_obj.fit_transform(sent_tokens)\n",
    "\n",
    "\n",
    "    # Cosine similarity\n",
    "    # In this case tfidf = [t1, 12, t3, t4, user_query]\n",
    "    # Get the last element (user_query) which is in index [-1] and compare it with the entire list (t1, t2, t3, t4....)\n",
    "\n",
    "    sim_values = cosine_similarity(tfidf[-1],tfidf) # Cosine similarity of the last element with the entire list\n",
    "\n",
    "    # Selecting the token with masimum similarity value\n",
    "    # -2 means the second last response -> because the last response ([-1]) is the user query\n",
    "    index = sim_values.argsort()[0][-2] # Sorting values to give the index\n",
    "\n",
    "\n",
    "    flattened_sim = sim_values.flatten() #Flattening the sim_values to make them one dimensional\n",
    "    flattened_sim.sort() # Sorting flattened sim_values\n",
    "\n",
    "    required_tfidf = flattened_sim[-2]\n",
    "\n",
    "    if(required_tfidf ==0):\n",
    "        bot_response += \"Sorry, I cannot understand your question. I can only respond to questions in my corpus\"\n",
    "        return bot_response()\n",
    "    else:\n",
    "        bot_response += bot_response + sent_tokens[index]\n",
    "        return respond(bot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a546c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHATBOT\n",
      "Who is Francine Rivers\n"
     ]
    }
   ],
   "source": [
    "print('CHATBOT')\n",
    "flag = 1\n",
    "\n",
    "while (flag == 1):\n",
    "    user_query = input()\n",
    "    user_query = user_query.lower()\n",
    "\n",
    "    # If user wants to exit\n",
    "    if(user_query == 'exit'):\n",
    "        flag == 0\n",
    "        print('ChatBot : Bye! I\\'m glad to be of assistance to you:)')\n",
    "\n",
    "    else:\n",
    "        # If user enters a greeting\n",
    "        if(greeting(user_query)!= None):\n",
    "            print(\"Bot: \" +greeting(user_query))\n",
    "        else:\n",
    "            res = respond(user_query)\n",
    "            print(\"Chatbot: \", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf1fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
